{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.loadtxt(\"1.txt\")\n",
    "#X=pd.read_csv(\"Kmer4.csv\",header=None)\n",
    "y=pd.read_csv(\"lable.txt\",header=None)\n",
    "y=np.array(y)\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier1(X,y):\n",
    "    print(datetime.datetime.now())\n",
    "    param1=[\"best\",\"random\"]\n",
    "    param_grid={\"splitter\":param1}\n",
    "    grid_search=GridSearchCV(DecisionTreeClassifier(random_state=10),param_grid,scoring=\"accuracy\",cv=cv)\n",
    "    grid_search.fit(X,y)\n",
    "    return grid_search.best_params_[\"splitter\"]\n",
    "def my_classifier2(p1,X,y):\n",
    "    print(datetime.datetime.now())\n",
    "    param2=np.array(range(3,10,1))\n",
    "    param_grid={\"max_depth\":param2}\n",
    "    grid_search=GridSearchCV(DecisionTreeClassifier(random_state=10,splitter=p1),param_grid,scoring=\"accuracy\",cv=cv)\n",
    "    grid_search.fit(X,y)\n",
    "    return grid_search.best_params_[\"max_depth\"]\n",
    "def my_classifier(p1,p2,X, y):\n",
    "    print(datetime.datetime.now())\n",
    "   # param2=[\"best\",\"random\"]   ##设置splitter范围\n",
    "   # param3=np.array(range(3,10,1))   ##设置max_depth范围\n",
    "    i=X.shape[1]\n",
    "    param3=np.array(range(1,i,100))  ## 设置max_features范围\n",
    "    param_grid={\"max_features\":param3}\n",
    "    grid_search=GridSearchCV(DecisionTreeClassifier(random_state=10,splitter=p1,max_depth=p2),param_grid,scoring=\"accuracy\",cv=cv)\n",
    "    grid_search.fit(X,y)\n",
    "#     print(datetime.datetime.now())\n",
    "#     print(\"best parameters:{}\".format(grid_search.best_params_))                        #输出最优网格化参数\n",
    "#     print(\"best cross-validation score:{:.3f}\".format(grid_search.best_score_))         #成员提供优化过程中观察到的最好评分\n",
    "#     print(\"best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "    Predict_Y=[]    #存放预测值\n",
    "    Prob_Y=[]       #存放预测概率\n",
    "    Really_Y=y  #存放真实标签\n",
    "    for train_index,test_index in cv.split(X):\n",
    "        estimator=DecisionTreeClassifier(random_state=10,splitter=p1,max_depth=p2,max_features=grid_search.best_params_[\"max_features\"])\n",
    "        estimator.fit(X[train_index],y[train_index])\n",
    "        Predict_Y.append(estimator.predict(X[test_index])[0])\n",
    "        Prob_Y.append(estimator.predict_proba(X[test_index]))\n",
    "    Prob_Y=np.array(Prob_Y)  #将Prob_Y改为numpy数组形式\n",
    "    Prob_Y=Prob_Y.reshape(173,2)  #原本是(173,1,2)形状，改为（173,2）形状\n",
    "    Prob_Y=pd.DataFrame(Prob_Y)\n",
    "    Prob_Y.columns=[\"0\",\"1\"]\n",
    "    confusion_matrix(Really_Y,Predict_Y)\n",
    "    TN=confusion_matrix(Really_Y,Predict_Y)[0,0]\n",
    "    FN=confusion_matrix(Really_Y,Predict_Y)[1,0]\n",
    "    FP=confusion_matrix(Really_Y,Predict_Y)[0,1]\n",
    "    TP=confusion_matrix(Really_Y,Predict_Y)[1,1]\n",
    "    ACC=accuracy_score(Really_Y,Predict_Y)\n",
    "    F1_score=f1_score(Really_Y,Predict_Y)\n",
    "    AUC=roc_auc_score(Really_Y,np.array(Prob_Y[\"1\"]))\n",
    "    Recall=recall_score(Really_Y,Predict_Y)\n",
    "    Precision=precision_score(Really_Y,Predict_Y)\n",
    "    S=p1\n",
    "    D=p2\n",
    "    M=grid_search.best_params_[\"max_features\"]\n",
    "#     print(\"ACC:\",ACC)\n",
    "#     print(\"f1_score:\",F1_score)\n",
    "#     print(\"AUC:\",AUC)\n",
    "    return TN,FN,FP,TP,ACC,Recall,Precision,F1_score,AUC,S,D,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "6.txt\n",
      "**************************************************\n",
      "2022-02-14 05:30:06.123330\n",
      "2022-02-14 05:30:29.732164\n",
      "2022-02-14 05:31:24.954965\n",
      "['6.txt' '33' '8' '55' '77' '0.6358381502890174' '0.9058823529411765'\n",
      " '0.5833333333333334' '0.7096774193548387' '0.6225935828877005' 'random'\n",
      " '9' '501']\n",
      "[array(['6.txt', '33', '8', '55', '77', '0.6358381502890174',\n",
      "       '0.9058823529411765', '0.5833333333333334', '0.7096774193548387',\n",
      "       '0.6225935828877005', 'random', '9', '501'], dtype='<U18')]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'E:\\datatest\\Kmer\\k2' # 文件夹目录\n",
    "files = os.listdir(file_path)\n",
    "results = []\n",
    "transfer=StandardScaler()\n",
    "for file in files:\n",
    "    print('#'*50)\n",
    "    path_whole = file_path + '\\\\' + file\n",
    "    a=np.loadtxt(path_whole)\n",
    "    #a=np.array(a)\n",
    "    x=transfer.fit_transform(a) \n",
    "    print(file)\n",
    "    print('*'*50)\n",
    "    x1=my_classifier1(x,y)\n",
    "    x2=my_classifier2(x1,x,y)\n",
    "    TN,FN,FP,TP,Acc,Rec,Pre,F,AUROC,S,D,M = my_classifier(x1,x2,x, y)\n",
    "    result = np.array([file,TN,FN,FP,TP,Acc,Rec,Pre,F,AUROC,S,D,M])\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "print(results)\n",
    "results = np.array(results)\n",
    "#print(results.shape)\n",
    "result_final = pd.DataFrame(results)\n",
    "#print(result_final)\n",
    "result_final.to_csv(file_path+'\\\\'+'result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
