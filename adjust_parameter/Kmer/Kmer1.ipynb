{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=LeaveOneOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.loadtxt(\"1.txt\")\n",
    "#X=pd.read_csv(\"Kmer4.csv\",header=None)\n",
    "y=pd.read_csv(\"lable.txt\",header=None)\n",
    "y=np.array(y)\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_classifier1(X,y):\n",
    "    print(datetime.datetime.now())\n",
    "    param1=[\"best\",\"random\"]\n",
    "    TN_a=[]\n",
    "    FN_a=[]\n",
    "    FP_a=[]\n",
    "    TP_a=[]\n",
    "    accuracy_a=[]\n",
    "    pre_a=[]\n",
    "    rec_a=[]\n",
    "    f1_a=[]\n",
    "    auroc_a=[]\n",
    "    param1=[\"best\",\"random\"]\n",
    "for i in param1:\n",
    "    Predict_Y=[]    #存放预测值\n",
    "    Prob_Y=[]       #存放预测概率\n",
    "    Really_Y=Standard_Y\n",
    "    for train_index,test_index in cv.split(Standard_X):\n",
    "        estimator=DecisionTreeClassifier(random_state=10,splitter=i)\n",
    "        estimator.fit(Standard_X[train_index],Standard_Y[train_index])\n",
    "        Predict_Y.append(estimator.predict(Standard_X[test_index])[0])\n",
    "        Prob_Y.append(estimator.predict_proba(Standard_X[test_index]))\n",
    "    Prob_Y=np.array(Prob_Y)  #将Prob_Y改为numpy数组形式\n",
    "    Prob_Y=Prob_Y.reshape(173,2)  #原本是(173,1,2)形状，改为（173,2）形状\n",
    "    import pandas as pd\n",
    "    Prob_Y=pd.DataFrame(Prob_Y)\n",
    "    Prob_Y.columns=[\"0\",\"1\"]\n",
    "    confusion_matrix(Really_Y,Predict_Y)\n",
    "    TN=confusion_matrix(Really_Y,Predict_Y)[0,0]\n",
    "    FN=confusion_matrix(Really_Y,Predict_Y)[1,0]\n",
    "    FP=confusion_matrix(Really_Y,Predict_Y)[0,1]\n",
    "    TP=confusion_matrix(Really_Y,Predict_Y)[1,1]\n",
    "    ACC=accuracy_score(Really_Y,Predict_Y)\n",
    "    Precision=precision_score(Really_Y,Predict_Y)\n",
    "    Recall=recall_score(Really_Y,Predict_Y)\n",
    "    F1_score=f1_score(Really_Y,Predict_Y)\n",
    "    AUC=roc_auc_score(Really_Y,np.array(Prob_Y[\"1\"]))\n",
    "    \n",
    "    TN_a.append(TN)\n",
    "    FN_a.append(FN)\n",
    "    FP_a.append(FP)\n",
    "    TP_a.append(TP)\n",
    "    accuracy_a.append(ACC)\n",
    "    pre_a.append(Precision)\n",
    "    rec_a.append(Recall)\n",
    "    f1_a.append(F1_score)\n",
    "    auroc_a.append(AUC)  \n",
    "results=np.array([param1,TN_a,FN_a,FP_a,TP_a,accuracy_a,pre_a,rec_a,f1_a,auroc_a])\n",
    "result_final = pd.DataFrame(results)\n",
    "result_final.to_csv('K1.csv',index=False)\n",
    "    param_grid={\"splitter\":param1}\n",
    "    grid_search=GridSearchCV(DecisionTreeClassifier(random_state=10),param_grid,scoring=\"accuracy\",cv=cv)\n",
    "    grid_search.fit(X,y)\n",
    "    return grid_search.best_params_[\"splitter\"]\n",
    "def my_classifier2(p1,X,y):\n",
    "    print(datetime.datetime.now())\n",
    "    param2=np.array(range(3,10,1))\n",
    "    param_grid={\"max_depth\":param2}\n",
    "    grid_search=GridSearchCV(DecisionTreeClassifier(random_state=10,splitter=p1),param_grid,scoring=\"accuracy\",cv=cv)\n",
    "    grid_search.fit(X,y)\n",
    "    return grid_search.best_params_[\"max_depth\"]\n",
    "def my_classifier(p1,p2,X, y):\n",
    "    print(datetime.datetime.now())\n",
    "   # param2=[\"best\",\"random\"]   ##设置splitter范围\n",
    "   # param3=np.array(range(3,10,1))   ##设置max_depth范围\n",
    "    i=X.shape[1]\n",
    "    param3=np.array(range(1,i,1))  ## 设置max_features范围\n",
    "    param_grid={\"max_features\":param3}\n",
    "    grid_search=GridSearchCV(DecisionTreeClassifier(random_state=10,splitter=p1,max_depth=p2),param_grid,scoring=\"accuracy\",cv=cv)\n",
    "    grid_search.fit(X,y)\n",
    "#     print(datetime.datetime.now())\n",
    "#     print(\"best parameters:{}\".format(grid_search.best_params_))                        #输出最优网格化参数\n",
    "#     print(\"best cross-validation score:{:.3f}\".format(grid_search.best_score_))         #成员提供优化过程中观察到的最好评分\n",
    "#     print(\"best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "    Predict_Y=[]    #存放预测值\n",
    "    Prob_Y=[]       #存放预测概率\n",
    "    Really_Y=y  #存放真实标签\n",
    "    for train_index,test_index in cv.split(X):\n",
    "        estimator=DecisionTreeClassifier(random_state=10,splitter=p1,max_depth=p2,max_features=grid_search.best_params_[\"max_features\"])\n",
    "        estimator.fit(X[train_index],y[train_index])\n",
    "        Predict_Y.append(estimator.predict(X[test_index])[0])\n",
    "        Prob_Y.append(estimator.predict_proba(X[test_index]))\n",
    "    Prob_Y=np.array(Prob_Y)  #将Prob_Y改为numpy数组形式\n",
    "    Prob_Y=Prob_Y.reshape(173,2)  #原本是(173,1,2)形状，改为（173,2）形状\n",
    "    Prob_Y=pd.DataFrame(Prob_Y)\n",
    "    Prob_Y.columns=[\"0\",\"1\"]\n",
    "    confusion_matrix(Really_Y,Predict_Y)\n",
    "    TN=confusion_matrix(Really_Y,Predict_Y)[0,0]\n",
    "    FN=confusion_matrix(Really_Y,Predict_Y)[1,0]\n",
    "    FP=confusion_matrix(Really_Y,Predict_Y)[0,1]\n",
    "    TP=confusion_matrix(Really_Y,Predict_Y)[1,1]\n",
    "    ACC=accuracy_score(Really_Y,Predict_Y)\n",
    "    F1_score=f1_score(Really_Y,Predict_Y)\n",
    "    AUC=roc_auc_score(Really_Y,np.array(Prob_Y[\"1\"]))\n",
    "    Recall=recall_score(Really_Y,Predict_Y)\n",
    "    Precision=precision_score(Really_Y,Predict_Y)\n",
    "    S=p1\n",
    "    D=p2\n",
    "    M=grid_search.best_params_[\"max_features\"]\n",
    "#     print(\"ACC:\",ACC)\n",
    "#     print(\"f1_score:\",F1_score)\n",
    "#     print(\"AUC:\",AUC)\n",
    "    return TN,FN,FP,TP,ACC,Recall,Precision,F1_score,AUC,S,D,M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "1.txt\n",
      "**************************************************\n",
      "2022-02-14 05:27:40.032128\n",
      "2022-02-14 05:27:40.500864\n",
      "2022-02-14 05:27:42.252182\n",
      "['1.txt' '31' '7' '57' '78' '0.630057803468208' '0.9176470588235294'\n",
      " '0.5777777777777777' '0.709090909090909' '0.33449197860962565' 'best' '4'\n",
      " '2']\n",
      "##################################################\n",
      "2.txt\n",
      "**************************************************\n",
      "2022-02-14 05:27:43.063009\n",
      "2022-02-14 05:27:43.651435\n",
      "2022-02-14 05:27:45.116515\n",
      "['2.txt' '48' '25' '40' '60' '0.6242774566473989' '0.7058823529411765'\n",
      " '0.6' '0.6486486486486486' '0.628475935828877' 'random' '4' '4']\n",
      "##################################################\n",
      "3.txt\n",
      "**************************************************\n",
      "2022-02-14 05:27:48.549331\n",
      "2022-02-14 05:27:49.595532\n",
      "2022-02-14 05:27:51.827560\n",
      "['3.txt' '76' '26' '12' '59' '0.7803468208092486' '0.6941176470588235'\n",
      " '0.8309859154929577' '0.7564102564102564' '0.6572192513368984' 'random'\n",
      " '3' '57']\n",
      "##################################################\n",
      "4.txt\n",
      "**************************************************\n",
      "2022-02-14 05:28:09.562111\n",
      "2022-02-14 05:28:11.268546\n",
      "2022-02-14 05:28:16.876542\n",
      "['4.txt' '69' '14' '19' '71' '0.8092485549132948' '0.8352941176470589'\n",
      " '0.7888888888888889' '0.8114285714285714' '0.8286764705882353' 'random'\n",
      " '9' '163']\n",
      "##################################################\n",
      "5.txt\n",
      "**************************************************\n",
      "2022-02-14 05:30:25.889446\n",
      "2022-02-14 05:30:32.003119\n",
      "2022-02-14 05:30:53.472198\n",
      "['5.txt' '77' '20' '11' '65' '0.8208092485549133' '0.7647058823529411'\n",
      " '0.8552631578947368' '0.8074534161490684' '0.7673796791443851' 'best' '8'\n",
      " '490']\n",
      "[array(['1.txt', '31', '7', '57', '78', '0.630057803468208',\n",
      "       '0.9176470588235294', '0.5777777777777777', '0.709090909090909',\n",
      "       '0.33449197860962565', 'best', '4', '2'], dtype='<U19'), array(['2.txt', '48', '25', '40', '60', '0.6242774566473989',\n",
      "       '0.7058823529411765', '0.6', '0.6486486486486486',\n",
      "       '0.628475935828877', 'random', '4', '4'], dtype='<U18'), array(['3.txt', '76', '26', '12', '59', '0.7803468208092486',\n",
      "       '0.6941176470588235', '0.8309859154929577', '0.7564102564102564',\n",
      "       '0.6572192513368984', 'random', '3', '57'], dtype='<U18'), array(['4.txt', '69', '14', '19', '71', '0.8092485549132948',\n",
      "       '0.8352941176470589', '0.7888888888888889', '0.8114285714285714',\n",
      "       '0.8286764705882353', 'random', '9', '163'], dtype='<U18'), array(['5.txt', '77', '20', '11', '65', '0.8208092485549133',\n",
      "       '0.7647058823529411', '0.8552631578947368', '0.8074534161490684',\n",
      "       '0.7673796791443851', 'best', '8', '490'], dtype='<U18')]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'E:\\datatest\\Kmer\\k1' # 文件夹目录\n",
    "files = os.listdir(file_path)\n",
    "results = []\n",
    "transfer=StandardScaler()\n",
    "for file in files:\n",
    "    print('#'*50)\n",
    "    path_whole = file_path + '\\\\' + file\n",
    "    a=np.loadtxt(path_whole)\n",
    "    #a=np.array(a)\n",
    "    x=transfer.fit_transform(a) \n",
    "    print(file)\n",
    "    print('*'*50)\n",
    "    x1=my_classifier1(x,y)\n",
    "    x2=my_classifier2(x1,x,y)\n",
    "    TN,FN,FP,TP,Acc,Rec,Pre,F,AUROC,S,D,M = my_classifier(x1,x2,x, y)\n",
    "    result = np.array([file,TN,FN,FP,TP,Acc,Rec,Pre,F,AUROC,S,D,M])\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "print(results)\n",
    "results = np.array(results)\n",
    "#print(results.shape)\n",
    "result_final = pd.DataFrame(results)\n",
    "#print(result_final)\n",
    "result_final.to_csv(file_path+'\\\\'+'result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
